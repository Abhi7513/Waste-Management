{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load image URL list from CSV\n",
    "df = pd.read_csv(\"all_image_urls.csv\", header=None, names=[\"url\"])\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define category ranges\n",
    "category_ranges = {\n",
    "    \"plastic\": (0, 49),\n",
    "    \"organic\": (50, 99),\n",
    "    \"recyclable\": (100, 149),\n",
    "    \"hazardous\": (150, 199),\n",
    "}\n",
    "\n",
    "# Create base directory\n",
    "base_dir = \"waste_dataset\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Download and save images into categorized folders\n",
    "for category, (start, end) in category_ranges.items():\n",
    "    category_dir = os.path.join(base_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(start, min(end + 1, len(df))):\n",
    "        try:\n",
    "            url = df.loc[i, \"url\"]\n",
    "            filename = f\"{category}_{i}.jpg\"\n",
    "            save_path = os.path.join(category_dir, filename)\n",
    "\n",
    "            r = requests.get(url, timeout=5)\n",
    "            if r.status_code == 200:\n",
    "                with open(save_path, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "            else:\n",
    "                print(f\"⚠ Skipped: {url} - Status {r.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error with index {i}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
